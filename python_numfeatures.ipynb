{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e72e9d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import check_random_state\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ecb0fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "seeds = np.random.permutation(5000)[:1400]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fc49a7",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d73ba4f",
   "metadata": {},
   "source": [
    "### Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a76927e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def sample_norm_covariates(n_datapoints, random_seed):\n",
    "    covariate = norm.rvs(1,0.3, size=n_datapoints, random_state = random_seed)\n",
    "    covariate[covariate <0] = 0\n",
    "    return covariate\n",
    "    \n",
    "def sample_uniform_covariates(n_datapoints,rng):\n",
    "    covariate = rng.uniform(low=0, high=1.0, size=n_datapoints).round(decimals=6)\n",
    "    return covariate\n",
    "\n",
    "def sample_categorical_covariates(n_datapoints, rng, cat_number):\n",
    "    covariate = rng.choice(cat_number, size=n_datapoints)\n",
    "    return covariate\n",
    "\n",
    "def sample_dataframe(n_datapoints, n_norm, n_unif, n_cat, random_seed):\n",
    "    \n",
    "    rng = np.random.RandomState(random_seed)\n",
    "    \n",
    "    norm_cov = np.transpose([sample_norm_covariates(n_datapoints,rng) for i in range(n_norm)])\n",
    "    unif_cov = np.transpose([sample_uniform_covariates(n_datapoints,rng) for i in range(n_unif)])\n",
    "    cat_cov = np.transpose([sample_categorical_covariates(n_datapoints,rng, 3) for i in range(n_cat)])\n",
    "    \n",
    "    df = pd.DataFrame(norm_cov)\n",
    "    df = pd.concat([df,pd.DataFrame(unif_cov)],axis =1)\n",
    "    df = pd.concat([df,pd.DataFrame(cat_cov)],axis =1)\n",
    "    df = df.sample(frac = 1, axis = 1, random_state = random_seed)\n",
    "    df.columns = [f'X{i}' for i in range(n_norm+n_unif+n_cat)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328296da",
   "metadata": {},
   "source": [
    "### Hazards "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60424709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weibull_hazard(t, k=1., s=1., t_shift=100, base_rate=1e2):\n",
    "    # t_shift is a trick to avoid avoid negative powers at t=0 when k < 1.\n",
    "    t = t + t_shift\n",
    "    return base_rate * (k / s) * (t / s) ** (k - 1.)\n",
    "\n",
    "def type1_hazards(df, t):\n",
    "    baseline = weibull_hazard(t, k=0.003)\n",
    "    #s = ((df[\"X0\"]+df[\"X1\"])/2 * (1 - (df[\"X2\"]+df[\"X3\"])/2 )).to_numpy()\n",
    "    s = ((df[\"X0\"]+df[\"X1\"]+df[\"X2\"])/3 * (df[\"X3\"]+df[\"X4\"]+df[\"X5\"])/3 ).to_numpy()\n",
    "    return s.reshape(-1, 1) * baseline.reshape(1, -1)\n",
    "\n",
    "def type2_hazards(df, t):\n",
    "    # Weibull hazards with k = 1 is just a constant over time:\n",
    "    baseline = weibull_hazard(t, k=3, s=8e3)\n",
    "    s = (\n",
    "        ( (df[\"X6\"]+df[\"X7\"]+df[\"X8\"])/3 * (df[\"X9\"]+df[\"X10\"]+df[\"X11\"])/3  + .001) * (df[\"X12\"]+df[\"X13\"])/2\n",
    "    ).to_numpy()\n",
    "    return s.reshape(-1, 1) * baseline.reshape(1, -1)\n",
    "\n",
    "def type3_hazards(df, t):\n",
    "    return np.vstack([\n",
    "        0.5 * weibull_hazard(t, k=6 * x, s=4e3) * y\n",
    "        for x, y in zip((df[\"X14\"]+ df[\"X15\"]+df[\"X16\"])/3, (df[\"X17\"]+df[\"X18\"]+df[\"X19\"])/3)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bd5b7d",
   "metadata": {},
   "source": [
    "### Event Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e7b6dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import bernoulli\n",
    "\n",
    "def sample_events_by_type(hazards,total_days, random_state=None):\n",
    "    rng = check_random_state(random_state)\n",
    "    outcomes = bernoulli.rvs(hazards, random_state=rng)\n",
    "    any_event_mask = np.any(outcomes, axis=1)\n",
    "    duration = np.full(outcomes.shape[0], fill_value=total_days)\n",
    "    occurrence_rows, occurrence_cols = np.where(outcomes)\n",
    "    # Some individuals might have more than one event occurrence,\n",
    "    # we only keep the first one.\n",
    "    # ex: trials = [[0, 0, 1, 0, 1]] -> duration = 2\n",
    "    _, first_occurrence_idxs = np.unique(occurrence_rows, return_index=True)\n",
    "    duration[any_event_mask] = occurrence_cols[first_occurrence_idxs]\n",
    "    jitter = rng.rand(duration.shape[0])\n",
    "    return pd.DataFrame(dict(event=any_event_mask, duration=duration + jitter))\n",
    "\n",
    "\n",
    "def first_event(event_frames, event_ids, random_seed=None):\n",
    "    rng = check_random_state(random_seed)\n",
    "    event = np.zeros(event_frames[0].shape[0], dtype=np.int32)\n",
    "    max_duration = np.max([ef[\"duration\"].max() for ef in event_frames])\n",
    "    duration = np.full_like(event_frames[0][\"duration\"], fill_value=max_duration)\n",
    "    \n",
    "    out = pd.DataFrame(\n",
    "        {\n",
    "            \"event\": event,\n",
    "            \"duration\": duration,\n",
    "        }\n",
    "    )\n",
    "    for event_id, ef in zip(event_ids, event_frames):\n",
    "        mask = ef[\"event\"] & (ef[\"duration\"] < out[\"duration\"])\n",
    "        out.loc[mask, \"event\"] = event_id\n",
    "        out.loc[mask, \"duration\"] = ef.loc[mask, \"duration\"]\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c51cd0",
   "metadata": {},
   "source": [
    "### Censoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d672e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_censoring(occurrences, censoring_weight=0.5, frac = 1, offset=0, random_state=None):\n",
    "    n_datapoints = occurrences.shape[0]\n",
    "    rng = check_random_state(random_state)\n",
    "    max_duration = occurrences[\"duration\"].max()\n",
    "    censoring_durations = rng.randint(\n",
    "        low=offset, high=max_duration/frac, size=n_datapoints\n",
    "    )\n",
    "    # reduce censoring randomly by setting durations back to the max,\n",
    "    # effectively ensuring that a fraction of the datapoints will not\n",
    "    # be censured.\n",
    "    disabled_censoring_mask = rng.rand(n_datapoints) > censoring_weight\n",
    "    censoring_durations[disabled_censoring_mask] = max_duration\n",
    "    \n",
    "    out = occurrences.copy()\n",
    "    censor_mask = occurrences[\"duration\"] > censoring_durations\n",
    "    out.loc[censor_mask, \"event\"] = 0\n",
    "    out.loc[censor_mask, \"duration\"] = censoring_durations[censor_mask]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de2e35a",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d708cdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_competing_events(data,total_days, uniform_censoring_weight=1.0, frac=1, max_observation_duration=2000, random_seed=None):\n",
    "    \n",
    "    rng = check_random_state(random_seed)\n",
    "    t = np.linspace(0, total_days, total_days)\n",
    "    \n",
    "    hazard_funcs = [type1_hazards, type2_hazards, type3_hazards]\n",
    "    event_ids = np.arange(len(hazard_funcs)) + 1\n",
    "    all_hazards = np.asarray([hazard_func(data, t) for hazard_func in hazard_funcs])\n",
    "    \n",
    "    occurrences_by_type = [sample_events_by_type(all_hazards[i],total_days, random_state=rng) for i in range(all_hazards.shape[0])]\n",
    "    occurrences = first_event(occurrences_by_type, event_ids)\n",
    "    \n",
    "    censored_occurrences = uniform_censoring(occurrences, censoring_weight=uniform_censoring_weight, frac = frac, random_state=rng)\n",
    "    \n",
    "    if max_observation_duration is not None:\n",
    "        # censor all events after max_observation_duration\n",
    "        max_duration_mask = censored_occurrences[\"duration\"] > max_observation_duration\n",
    "        censored_occurrences.loc[max_duration_mask, \"duration\"] = max_observation_duration\n",
    "        censored_occurrences.loc[max_duration_mask, \"event\"] = 0\n",
    "    return (\n",
    "        censored_occurrences,\n",
    "        occurrences,\n",
    "        all_hazards  # shape = (n_event_types, n_observations, n_timesteps)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cec28e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(n_datapoints,total_days,frac, seed):\n",
    "    data = sample_dataframe(n_datapoints, 8, 6, 6, seed) \n",
    "    (events, events_uncensored, all_hazards) = sample_competing_events(data, total_days, frac=frac, random_seed= seed)\n",
    "    data['event'] = pd.Series(events['event'])\n",
    "    data['event'] = data['event'].replace(2,1)\n",
    "    data['event'] = data['event'].replace(3,1)\n",
    "    data['duration'] = pd.Series(events['duration'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43b7300",
   "metadata": {},
   "source": [
    "# Number of Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "522d5831",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8af5b5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sample_data(int(N),1200,0.2,seeds[0])\n",
    "perc = np.sum(data['event']==0)*100/len(data['event'])\n",
    "perc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d0c6f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of simulation: 101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sd = 0 \n",
    "for seed_ in seeds:\n",
    "    data = sample_data(int(N),1200,0.2,seed_)\n",
    "    perc = np.sum(data['event']==0)*100/len(data['event'])\n",
    "    if (48. <= perc <= 52.):\n",
    "        sd = sd+1\n",
    "        data.to_pickle(f\"numfeatdata_20_{sd}.pkl\")\n",
    "\n",
    "\n",
    "print(f'Number of simulation: {sd}')\n",
    "print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "28e5a090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.remove(f'numfeatdata_20_101.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12602c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
